# 3Sigma Partners â€” CAS Portfolio Analytics Dashboard
# -------------------------------------------------
# Streamlit app that lets a user upload a CAS (CSV/XLSX/PDF*),
# builds a clean transaction ledger, and renders a multi-tab dashboard
# with XIRR, benchmark comparisons (NIFTY 500/50/MID/SMALL),
# allocations (sector, market-cap), risk, and diagnostics.
#
# *PDF parsing for CAMS/KFin CAS is best-effort (layout varies). For reliability,
#  prefer CSV/XLSX exported ledgers. A sample template is auto-generated below.
#
# HOW TO RUN
#   1) pip install -r requirements.txt
#   2) streamlit run app.py
#
# requirements.txt (suggested)
#   streamlit
#   pandas
#   numpy
#   plotly
#   yfinance
#   python-dateutil
#   pdfminer.six
#   openpyxl
#   scipy
#
# Color palette: Blue, Grey, Gold (no overlapping hues per chart)
# ---------------------------------------------------------------

import io
import re
import math
import json
import base64
import warnings
from datetime import datetime, timedelta, date

import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
import streamlit as st

from dateutil.relativedelta import relativedelta

try:
    import yfinance as yf
except Exception:
    yf = None

warnings.filterwarnings("ignore")

# -----------------------
# App-wide configuration
# -----------------------
st.set_page_config(
    page_title="3Sigma CAS Portfolio Dashboard",
    page_icon="ðŸ“ˆ",
    layout="wide",
)

# Brand styling
PRIMARY_BLUE = "#0B5FA5"
SECONDARY_BLUE = "#2E86C1"
SOFT_BLUE = "#E8F1FA"
DARK_GREY = "#2B2F36"
MID_GREY = "#6B7280"
LIGHT_GREY = "#EEF2F7"
GOLD = "#C8A951"
GOLD_SOFT = "#F7F2E0"

BG_CARD = "#FFFFFF"

# Plotly theme helpers
px.defaults.template = "plotly_white"

COLOR_SETS = {
    "line": [PRIMARY_BLUE, GOLD, MID_GREY, SECONDARY_BLUE],
    "bars": [PRIMARY_BLUE, GOLD, MID_GREY, SECONDARY_BLUE, "#5DADE2", "#B7950B"],
    "pie": [PRIMARY_BLUE, GOLD, MID_GREY, SECONDARY_BLUE, "#4F6D7A", "#D4AF37"],
}

# -----------------------
# Utility: Sample Template
# -----------------------
SAMPLE_COLUMNS = [
    "Date", "Folio", "Scheme", "Transaction", "Amount", "Units", "NAV",
    "ISIN", "AMC", "Sector", "MarketCap", "CurrentValue"
]

SAMPLE_ROWS = [
    ["2021-01-05", "1234/56", "Nippon India Nifty 50", "Purchase", 100000, 500.0, 200.00, "INF204KB14I2", "Nippon", "Large Cap", "Large", None],
    ["2021-03-10", "1234/56", "Nippon India Nifty 50", "Purchase", 50000, 220.0, 227.27, "INF204KB14I2", "Nippon", "Large Cap", "Large", None],
    ["2022-07-18", "1234/57", "HDFC Midcap Opportunities", "Purchase", 75000, 300.0, 250.00, "INF179K01DN8", "HDFC", "Mid Cap", "Mid", None],
    ["2023-02-01", "1234/57", "HDFC Midcap Opportunities", "Dividend Reinvest", 2500, 10.0, 250.00, "INF179K01DN8", "HDFC", "Mid Cap", "Mid", None],
    ["2024-06-20", "1234/58", "Axis Small Cap", "Purchase", 60000, 240.0, 250.00, "INF846K01136", "Axis", "Small Cap", "Small", None],
]

# -----------------------
# Helper functions
# -----------------------

def _to_date(x):
    if pd.isna(x):
        return pd.NaT
    for fmt in ("%Y-%m-%d", "%d-%m-%Y", "%d/%m/%Y", "%Y/%m/%d", "%d-%b-%Y"):
        try:
            return pd.to_datetime(x, format=fmt)
        except Exception:
            continue
    return pd.to_datetime(x, errors="coerce")


def load_file(upload):
    """Load uploaded file into a canonical transactions DataFrame.
    Accepts CSV/XLSX. Attempts PDF via pdfminer (best-effort).
    Expected columns (case-insensitive, flexible names allowed):
      - Date
      - Scheme
      - Transaction (Purchase/Sell/Dividend Reinvest/...)
      - Amount (negative for redemptions if available; else we'll sign by type)
      - Units
      - NAV (optional)
      - Sector (optional)
      - MarketCap (Large/Mid/Small) (optional)
      - CurrentValue (optional, for valuation snapshots)
    """
    name = upload.name.lower()
    if name.endswith(".csv"):
        df = pd.read_csv(upload)
    elif name.endswith(".xlsx") or name.endswith(".xls"):
        df = pd.read_excel(upload)
    elif name.endswith(".pdf"):
        try:
            from pdfminer.high_level import extract_text
            text = extract_text(upload)
            # Very light-touch parsing: try to extract CSV-like rows using regex.
            # Users should prefer CSV/XLSX for accuracy.
            rows = []
            for line in text.splitlines():
                if re.search(r"\d{1,2}[-/][A-Za-z0-9]{3,9}[-/]\d{2,4}", line) or re.search(r"\d{4}[-/]\d{2}[-/]\d{2}", line):
                    parts = re.split(r"\s{2,}|\t|,", line.strip())
                    if len(parts) >= 5:
                        rows.append(parts[:12])
            df = pd.DataFrame(rows)
            df.columns = (SAMPLE_COLUMNS[: df.shape[1]])
        except Exception:
            st.error("PDF parsing is experimental. Please upload a CSV/XLSX per the template.")
            return None
    else:
        st.error("Unsupported file type. Please upload CSV, XLSX, or PDF.")
        return None

    # Normalize columns
    col_map = {}
    for c in df.columns:
        lc = c.strip().lower()
        if lc in ["date", "txn date", "transaction date"]:
            col_map[c] = "Date"
        elif lc in ["scheme", "scheme name", "fund"]:
            col_map[c] = "Scheme"
        elif lc in ["transaction", "txn type", "type", "trans type"]:
            col_map[c] = "Transaction"
        elif lc in ["amount", "amount (inr)", "value"]:
            col_map[c] = "Amount"
        elif lc in ["units", "qty"]:
            col_map[c] = "Units"
        elif lc in ["nav", "price"]:
            col_map[c] = "NAV"
        elif lc in ["sector"]:
            col_map[c] = "Sector"
        elif lc in ["marketcap", "market cap", "cap"]:
            col_map[c] = "MarketCap"
        elif lc in ["currentvalue", "current value", "valuation", "market value"]:
            col_map[c] = "CurrentValue"
        elif lc in ["isin"]:
            col_map[c] = "ISIN"
        elif lc in ["amc", "rta"]:
            col_map[c] = "AMC"
        else:
            col_map[c] = c
    df = df.rename(columns=col_map)

    # Basic cleaning
    if "Date" not in df.columns or "Scheme" not in df.columns:
        st.error("Missing essential columns (Date, Scheme). Please use the template.")
        return None

    df["Date"] = df["Date"].apply(_to_date)
    df = df.dropna(subset=["Date", "Scheme"]).copy()

    if "Transaction" not in df.columns:
        df["Transaction"] = "Purchase"

    # Compute signed Amount if not present
    if "Amount" in df.columns:
        df["Amount"] = pd.to_numeric(df["Amount"], errors="coerce").fillna(0.0)
        # If redemptions are positive, flip sign for sell
        mask_sell = df["Transaction"].str.contains("sell|redeem", case=False, na=False)
        df.loc[mask_sell & (df["Amount"] > 0), "Amount"] *= -1
    else:
        df["Amount"] = 0.0

    # Units numeric
    if "Units" in df.columns:
        df["Units"] = pd.to_numeric(df["Units"], errors="coerce").fillna(0.0)
    else:
        df["Units"] = np.nan

    if "NAV" in df.columns:
        df["NAV"] = pd.to_numeric(df["NAV"], errors="coerce")

    # Fill optional columns
    for opt in ["Sector", "MarketCap", "CurrentValue", "AMC", "ISIN"]:
        if opt not in df.columns:
            df[opt] = np.nan
    df["CurrentValue"] = pd.to_numeric(df["CurrentValue"], errors="coerce")

    df = df.sort_values("Date").reset_index(drop=True)
    return df


# -----------------------
# Finance math helpers
# -----------------------

def xnpv(rate, dates, cashflows):
    t0 = pd.to_datetime(dates).min()
    return sum(cf / (1 + rate) ** ((pd.to_datetime(d) - t0).days / 365.0) for cf, d in zip(cashflows, dates))


def xirr(dates, cashflows, guess=0.1):
    # Robust XIRR using bisection around a wide bracket
    dates = list(pd.to_datetime(dates))
    cashflows = list(map(float, cashflows))
    if abs(sum(cashflows)) < 1e-6:
        return 0.0
    low, high = -0.9999, 5.0
    for _ in range(200):
        mid = (low + high) / 2
        val = xnpv(mid, dates, cashflows)
        if abs(val) < 1e-7:
            return mid
        val_low = xnpv(low, dates, cashflows)
        if val_low * val < 0:
            high = mid
        else:
            low = mid
    return mid


def month_end(d):
    d = pd.to_datetime(d)
    return (d + pd.offsets.MonthEnd(0)).date()


# -----------------------
# Benchmark data
# -----------------------
BENCH_CONFIG = {
    "NIFTY 500": {
        "tickers": ["NIFTYBEES.NS"],  # proxy if NIFTY 500 NSE index not available; will fallback
    },
    "NIFTY 50": {
        "tickers": ["NIFTYBEES.NS"],
    },
    "NIFTY MIDCAP": {
        "tickers": ["NIFTYMID150.NS", "MIDCAPETF.NS", "ICICIM150.NS"],
    },
    "NIFTY SMALL": {
        "tickers": ["SMALLCAP.NS", "NISMALLCAP.NS", "MOTISLMS.NS"],
    },
}

@st.cache_data(show_spinner=False)
def fetch_benchmark_series(label: str, start: date, end: date) -> pd.Series:
    """Fetch monthly total-return-like proxy using closing prices.
    Prefers ETFs on Yahoo Finance. Falls back to synthetic series if offline.
    Returns a monthly series indexed by month-end with normalized starting value 100.
    """
    idx = pd.date_range(start, end, freq="M")
    if yf is None:
        # Offline fallback: 10% annual drift w/ noise
        rng = np.random.default_rng(42)
        rets = rng.normal(loc=(0.10/12), scale=0.04, size=len(idx))
        series = pd.Series(100 * (1 + pd.Series(rets)).cumprod(), index=idx)
        series.name = label
        return series

    tickers = BENCH_CONFIG.get(label, {}).get("tickers", [])
    for tkr in tickers:
        try:
            data = yf.download(tkr, start=start - relativedelta(months=2), end=end + relativedelta(days=3), progress=False, auto_adjust=True)
            if not data.empty:
                monthly = data["Close"].resample("M").last().dropna()
                series = 100 * (monthly / monthly.iloc[0])
                series.name = label
                return series.loc[idx.intersection(series.index)]
        except Exception:
            continue
    # final fallback synthetic
    rng = np.random.default_rng(7)
    rets = rng.normal(loc=(0.11/12), scale=0.05, size=len(idx))
    series = pd.Series(100 * (1 + pd.Series(rets)).cumprod(), index=idx)
    series.name = label
    return series


# -----------------------
# Portfolio engine
# -----------------------

def build_cashflows(df: pd.DataFrame, valuation_date: date, cur_value_by_scheme: dict | None = None):
    """Build cashflows per scheme and in total. Dividend reinvest is treated as no external cashflow (amount=0).
    Redemptions are positive cashflows (money back), Purchases are negatives.
    Adds terminal positive cashflow for current value at valuation_date.
    Returns dict: {scheme: DataFrame[Date, Cashflow]}
    """
    cf = {}
    for scheme, d in df.groupby("Scheme"):
        dd = d.copy()
        cash = []
        for _, r in dd.iterrows():
            typ = str(r.get("Transaction", "")).lower()
            amt = float(r.get("Amount", 0) or 0)
            if "purchase" in typ or "buy" in typ:
                cash.append((r["Date"], -abs(amt)))
            elif "sell" in typ or "redeem" in typ:
                cash.append((r["Date"], abs(amt)))
            elif "dividend" in typ and "reinvest" in typ:
                # internal reinvestment
                cash.append((r["Date"], 0.0))
            else:
                cash.append((r["Date"], amt))
        # terminal value
        term_val = None
        if cur_value_by_scheme and scheme in cur_value_by_scheme:
            term_val = float(cur_value_by_scheme[scheme])
        elif "CurrentValue" in dd.columns and dd["CurrentValue"].notna().any():
            term_val = float(dd["CurrentValue"].dropna().iloc[-1])
        if term_val is not None and term_val != 0:
            cash.append((pd.to_datetime(valuation_date), abs(term_val)))
        cf[scheme] = pd.DataFrame(cash, columns=["Date", "Cashflow"]).sort_values("Date")
    # total
    all_cash = pd.concat(list(cf.values())).groupby("Date", as_index=False)["Cashflow"].sum()
    cf["__TOTAL__"] = all_cash
    return cf


def portfolio_monthly_series(df: pd.DataFrame, valuation_date: date):
    """Build monthly series for invested (cumulative net contributions) and portfolio value.
    If CurrentValue not provided monthly, we approximate by carrying forward last known.
    """
    all_dates = pd.date_range(df["Date"].min(), valuation_date, freq="M")
    tx = df.copy()
    # external cashflows only
    m = tx["Transaction"].str.lower().fillna("")
    ext = tx[(m.str.contains("purchase|buy|sell|redeem"))].copy()
    ext.loc[m.str.contains("purchase|buy"), "SignedAmount"] = -ext.loc[m.str.contains("purchase|buy"), "Amount"].abs()
    ext.loc[m.str.contains("sell|redeem"), "SignedAmount"] = ext.loc[m.str.contains("sell|redeem"), "Amount"].abs()
    monthly_cf = ext.groupby(pd.Grouper(key="Date", freq="M"))["SignedAmount"].sum().reindex(all_dates, fill_value=0)

    # Portfolio value approximation
    if "CurrentValue" in df.columns and df["CurrentValue"].notna().any():
        latest_by_scheme = df.sort_values("Date").groupby("Scheme")["CurrentValue"].last()
        port_val = latest_by_scheme.sum()
        value_series = pd.Series(port_val, index=all_dates)
    else:
        # If units & nav available, last known NAV*units per scheme
        if {"Units", "NAV"}.issubset(df.columns):
            last_units = df.sort_values("Date").groupby("Scheme")["Units"].sum()
            last_nav = df.sort_values("Date").groupby("Scheme")["NAV"].last().fillna(0)
            est_val = float((last_units * last_nav).sum())
            value_series = pd.Series(est_val, index=all_dates)
        else:
            value_series = pd.Series(0.0, index=all_dates)

    invested_series = -monthly_cf.cumsum()
    return invested_series.rename("Invested"), value_series.rename("Portfolio")


def simulate_benchmark_from_cashflows(cashflow_df: pd.DataFrame, bench_series: pd.Series):
    """Given dated cashflows (negative invest, positive redeem) and a benchmark index series (value=100 base),
    simulate investing those cashflows into the benchmark and compute terminal value and XIRR.
    """
    # align to month end
    cf = cashflow_df.copy()
    cf["Date"] = cf["Date"].apply(month_end)
    bench = bench_series.copy()
    bench = bench / bench.iloc[0]

    units = 0.0
    last_idx = None
    for d, amt in zip(cf["Date"], cf["Cashflow"]):
        if d not in bench.index:
            continue
        px = bench.loc[d]
        if amt < 0:  # investment
            units += (-amt) / px
        else:  # redemption
            units -= amt / px
        last_idx = d
    terminal_value = units * bench.iloc[-1]

    # Build CFs for XIRR: use same CFs plus terminal value
    xirr_dates = list(cf["Date"]) + [bench.index[-1]]
    xirr_cfs = list(cf["Cashflow"]) + [terminal_value]
    rate = xirr(xirr_dates, xirr_cfs)
    return terminal_value, rate


# -----------------------
# UI â€” Sidebar
# -----------------------
st.sidebar.markdown(
    f"""
    <div style='padding:12px;border-radius:16px;background:{SOFT_BLUE};border:1px solid {PRIMARY_BLUE}'>
        <h3 style='margin:0;color:{PRIMARY_BLUE}'>3Sigma Partners</h3>
        <p style='margin:4px 0;color:{MID_GREY}'>CAS Portfolio Analytics</p>
    </div>
    """,
    unsafe_allow_html=True,
)

uploaded = st.sidebar.file_uploader("Upload CAS (CSV/XLSX/PDF). Need help? Download the template below.", type=["csv", "xlsx", "xls", "pdf"])
colA, colB = st.sidebar.columns([1,1])
with colA:
    if st.button("Download CSV Template"):
        buf = io.StringIO()
        pd.DataFrame(SAMPLE_ROWS, columns=SAMPLE_COLUMNS).to_csv(buf, index=False)
        st.download_button(
            label="Save Template",
            data=buf.getvalue(),
            file_name="cas_template_3sigma.csv",
            mime="text/csv",
        )
with colB:
    demo = st.toggle("Use Demo Data", value=False, help="Generate a small synthetic dataset if no file is uploaded.")

valuation_date = st.sidebar.date_input("Valuation Date", value=date.today())
default_bench = st.sidebar.selectbox("Default Benchmark", ["NIFTY 500", "NIFTY 50", "NIFTY MIDCAP", "NIFTY SMALL"], index=0)

# -----------------------
# Data Loading
# -----------------------
if uploaded is not None:
    data = load_file(uploaded)
else:
    data = None

if data is None and demo:
    data = pd.DataFrame(SAMPLE_ROWS, columns=SAMPLE_COLUMNS)

if data is None:
    st.info("Upload a CAS file or enable Demo Data to explore the dashboard.")
    st.stop()

# Filters
mind = pd.to_datetime(data["Date"]).min().date()
maxd = pd.to_datetime(data["Date"]).max().date()
start_date, end_date = st.sidebar.date_input("Filter Date Range", value=(mind, valuation_date), min_value=mind, max_value=valuation_date)

flt = (data["Date"] >= pd.to_datetime(start_date)) & (data["Date"] <= pd.to_datetime(end_date))
data = data.loc[flt].copy()

# -----------------------
# Engine: Cashflows & Benchmarks
# -----------------------
cf_by = build_cashflows(data, valuation_date)
monthly_invested, monthly_value = portfolio_monthly_series(data, valuation_date)
start_for_bench = min(monthly_invested.index.min(), pd.to_datetime(start_date))
end_for_bench = pd.to_datetime(valuation_date)

bench_series_cache = {name: fetch_benchmark_series(name, start_for_bench.date(), end_for_bench.date()) for name in BENCH_CONFIG.keys()}

# Total XIRR & Benchmark XIRR (NIFTY 500)
port_cf = cf_by["__TOTAL__"]
term_val, bench_total_xirr = simulate_benchmark_from_cashflows(port_cf, bench_series_cache["NIFTY 500"])  # as requested, compare XIRR vs NIFTY 500

port_dates = list(port_cf["Date"]) + [pd.to_datetime(valuation_date)]
port_cfs = list(port_cf["Cashflow"]) + [monthly_value.iloc[-1] if len(monthly_value)>0 else 0.0]
portfolio_xirr = xirr(port_dates, port_cfs)

# -----------------------
# Header KPIs
# -----------------------
top1, top2, top3, top4 = st.columns(4)
with top1:
    invested_total = (-port_cf["Cashflow"].clip(upper=0).sum())
    st.metric("Total Invested", f"â‚¹{invested_total:,.0f}")
with top2:
    port_val = float(monthly_value.iloc[-1]) if len(monthly_value) else 0.0
    st.metric("Portfolio Value", f"â‚¹{port_val:,.0f}")
with top3:
    pnl = port_val - invested_total
    st.metric("Unrealized P&L", f"â‚¹{pnl:,.0f}", delta=f"{(pnl/max(invested_total,1))*100:,.2f}%")
with top4:
    st.metric("Total XIRR", f"{portfolio_xirr*100:,.2f}%", delta=f"vs NIFTY 500: {(portfolio_xirr-bench_total_xirr)*100:,.2f}%")

st.markdown("---")

# -----------------------
# Tabs
# -----------------------
(
    tab_overview,
    tab_performance,
    tab_allocation,
    tab_risk,
    tab_transactions,
    tab_diagnostics,
) = st.tabs([
    "Overview",
    "Performance",
    "Allocations",
    "Risk",
    "Transactions",
    "Diagnostics",
])

# -----------------------
# Overview Tab
# -----------------------
with tab_overview:
    st.subheader("Portfolio vs Benchmarks")

    bench_choice = st.selectbox("Benchmark for overlay", list(BENCH_CONFIG.keys()), index=list(BENCH_CONFIG.keys()).index(default_bench))
    bench_series = bench_series_cache[bench_choice]

    # Build benchmark value using same monthly contributions
    bench_val, bench_x = simulate_benchmark_from_cashflows(port_cf, bench_series)

    # Build series for plotting: monthly invested, portfolio value, benchmark value
    idx = monthly_invested.index
    bench_norm = bench_series / bench_series.iloc[0]

    # simulate value curve month by month
    cf_m = port_cf.copy()
    cf_m["Date"] = cf_m["Date"].apply(month_end)
    contrib = cf_m.groupby("Date")["Cashflow"].sum().reindex(idx, fill_value=0)

    # Portfolio series already available (monthly_value)
    # Benchmark value series simulation
    units = 0.0
    bvals = []
    for d in idx:
        px = bench_norm.loc[bench_norm.index.get_indexer([d], method='nearest')[0]] if d in bench_norm.index else (bench_norm.iloc[-1] if len(bench_norm)>0 else 1)
        c = contrib.loc[d]
        if c < 0:  # invest
            units += (-c) / px
        else:      # redeem
            units -= c / px
        bvals.append(units * px)
    bench_curve = pd.Series(bvals, index=idx, name=f"Benchmark Sim ({bench_choice})")

    df_plot = pd.DataFrame({
        "Invested": monthly_invested,
        "Portfolio": monthly_value,
        f"Benchmark Sim ({bench_choice})": bench_curve * (monthly_invested.iloc[0]*0 + 100000)  # scale similar to rupees for readability
    })

    fig = go.Figure()
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["Invested"], mode='lines', name='Invested', line=dict(color=COLOR_SETS["line"][2], width=2)))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot["Portfolio"], mode='lines', name='Portfolio Value', line=dict(color=COLOR_SETS["line"][0], width=3)))
    fig.add_trace(go.Scatter(x=df_plot.index, y=df_plot.iloc[:,2], mode='lines', name=df_plot.columns[2], line=dict(color=COLOR_SETS["line"][1], width=2, dash='dash')))
    fig.update_layout(
        height=480,
        legend=dict(orientation='h', yanchor='bottom', y=1.02, xanchor='right', x=1),
        margin=dict(l=10, r=10, t=10, b=10),
        plot_bgcolor=LIGHT_GREY,
        paper_bgcolor="white",
    )
    st.plotly_chart(fig, use_container_width=True)

    st.caption("Line chart shows monthly invested amount (cumulative), estimated portfolio value, and simulated benchmark value using identical cashflows.")

# -----------------------
# Performance Tab
# -----------------------
with tab_performance:
    st.subheader("XIRR by Investment vs NIFTY 500 XIRR")

    rows = []
    for scheme, cf in cf_by.items():
        if scheme == "__TOTAL__":
            continue
        # Scheme XIRR
        dts = list(cf["Date"]) + [pd.to_datetime(valuation_date)]
        # terminal: approximate with last known CurrentValue per scheme if present
        term = data.loc[data["Scheme"]==scheme, "CurrentValue"].dropna()
        terminal = float(term.iloc[-1]) if len(term)>0 else 0.0
        cfs = list(cf["Cashflow"]) + [terminal]
        r = xirr(dts, cfs)

        # Benchmark XIRR (NIFTY 500) for the same cashflows
        _, r_bench = simulate_benchmark_from_cashflows(cf, bench_series_cache["NIFTY 500"])  # as requested
        rows.append({"Scheme": scheme, "XIRR": r*100, "NIFTY 500 XIRR": r_bench*100, "Alpha (pp)": (r - r_bench)*100})

    xirr_df = pd.DataFrame(rows).sort_values("Alpha (pp)", ascending=False)
    st.dataframe(xirr_df, use_container_width=True)

    st.markdown("### Index Returns Snapshot (since your first transaction)")
    first_dt = pd.to_datetime(data["Date"]).min().date()
    idx_cols = []
    for name, ser in bench_series_cache.items():
        ret = (ser.iloc[-1] / ser.iloc[0] - 1) * 100
        idx_cols.append({"Index": name, "Return %": round(ret,2)})
    idx_df = pd.DataFrame(idx_cols).sort_values("Index")
    c1, c2 = st.columns([2,1])
    with c1:
        st.dataframe(idx_df, use_container_width=True)
    with c2:
        figb = px.bar(idx_df, x="Index", y="Return %", color="Index", color_discrete_sequence=COLOR_SETS["bars"])
        figb.update_layout(showlegend=False, height=320, margin=dict(l=10,r=10,t=10,b=10), plot_bgcolor=GOLD_SOFT)
        st.plotly_chart(figb, use_container_width=True)

# -----------------------
# Allocations Tab
# -----------------------
with tab_allocation:
    st.subheader("Allocation Views")
    # Market Cap
    if "MarketCap" in data.columns and data["MarketCap"].notna().any():
        mk_df = data.sort_values("Date").groupby(["Scheme","MarketCap"])  \
            .agg({"Units":"sum","CurrentValue":"last"}).reset_index()
        mk_df["Weight"] = mk_df["CurrentValue"].fillna(0)
        pie1 = px.pie(mk_df.groupby("MarketCap")["Weight"].sum().reset_index(), names="MarketCap", values="Weight",
                      color="MarketCap", color_discrete_sequence=COLOR_SETS["pie"], hole=0.45)
        pie1.update_layout(height=380, title_text="Market-Cap Allocation", title_x=0.5)
        st.plotly_chart(pie1, use_container_width=True)
    else:
        st.info("MarketCap column not found. Populate Large/Mid/Small to enable this view.")

    # Sector
    if "Sector" in data.columns and data["Sector"].notna().any():
        sec_df = data.sort_values("Date").groupby(["Scheme","Sector"]).agg({"CurrentValue":"last"}).reset_index()
        sec_bar = px.bar(sec_df.groupby("Sector")["CurrentValue"].sum().sort_values(ascending=False).reset_index(),
                         x="Sector", y="CurrentValue", color="Sector", color_discrete_sequence=COLOR_SETS["bars"]) \
                    .update_layout(height=420, title_text="Sector Allocation", title_x=0.5, showlegend=False)
        st.plotly_chart(sec_bar, use_container_width=True)
    else:
        st.info("Sector column not found. Add sector tags for better insights.")

    # AMC exposure
    if "AMC" in data.columns and data["AMC"].notna().any():
        amc_df = data.sort_values("Date").groupby("AMC").agg({"CurrentValue":"last"}).reset_index()
        amc_df = amc_df.sort_values("CurrentValue", ascending=False).head(15)
        amc_bar = px.bar(amc_df, x="AMC", y="CurrentValue", color="AMC", color_discrete_sequence=COLOR_SETS["bars"]).update_layout(showlegend=False, height=360, title_text="AMC Exposure", title_x=0.5)
        st.plotly_chart(amc_bar, use_container_width=True)

# -----------------------
# Risk Tab
# -----------------------
with tab_risk:
    st.subheader("Risk & Drawdowns (Portfolio Approx)")

    # Approximate portfolio NAV series from monthly_value
    nav = monthly_value.replace(0, np.nan).ffill()
    ret = nav.pct_change().dropna()
    if len(ret) > 3:
        vol = ret.std() * math.sqrt(12)
        dd = (nav / nav.cummax() - 1).min()
        st.metric("Annualized Volatility", f"{vol*100:,.2f}%")
        st.metric("Max Drawdown", f"{dd*100:,.2f}%")

        # Drawdown curve
        dd_series = nav / nav.cummax() - 1
        figdd = go.Figure()
        figdd.add_trace(go.Scatter(x=dd_series.index, y=dd_series.values, mode='lines', name='Drawdown', line=dict(color=GOLD)))
        figdd.update_layout(height=320, margin=dict(l=10,r=10,t=10,b=10), yaxis_tickformat=",.0%", plot_bgcolor=LIGHT_GREY)
        st.plotly_chart(figdd, use_container_width=True)

        # Beta vs selected benchmark
        bench_for_beta = st.selectbox("Benchmark for Beta", list(BENCH_CONFIG.keys()), index=0)
        bser = bench_series_cache[bench_for_beta]
        bret = bser.pct_change().dropna()
        # align
        dfb = pd.DataFrame({"p": ret, "b": bret}).dropna()
        if len(dfb) > 3:
            cov = np.cov(dfb["p"], dfb["b"])[0,1]
            beta = cov / np.var(dfb["b"]) if np.var(dfb["b"])>0 else np.nan
            st.metric("Beta (monthly)", f"{beta:,.2f}")

            sc = px.scatter(dfb, x="b", y="p", trendline="ols", labels={"b":"Benchmark Returns", "p":"Portfolio Returns"}, color_discrete_sequence=[PRIMARY_BLUE])
            sc.update_layout(height=360, plot_bgcolor=SOFT_BLUE)
            st.plotly_chart(sc, use_container_width=True)
    else:
        st.info("Not enough history to compute risk stats.")

# -----------------------
# Transactions Tab
# -----------------------
with tab_transactions:
    st.subheader("Transaction Ledger")
    show_cols = [c for c in ["Date","Scheme","Transaction","Amount","Units","NAV","Sector","MarketCap","AMC","CurrentValue"] if c in data.columns]
    st.dataframe(data[show_cols].sort_values("Date"), use_container_width=True)

    st.markdown("### Monthly Cashflow Heatmap")
    d = data.copy()
    d["Signed"] = 0.0
    m = d["Transaction"].str.lower().fillna("")
    d.loc[m.str.contains("purchase|buy"), "Signed"] = -d.loc[m.str.contains("purchase|buy"), "Amount"].abs()
    d.loc[m.str.contains("sell|redeem"), "Signed"] = d.loc[m.str.contains("sell|redeem"), "Amount"].abs()
    d["Year"] = d["Date"].dt.year
    d["Month"] = d["Date"].dt.month_name().str[:3]
    piv = d.pivot_table(index="Year", columns="Month", values="Signed", aggfunc="sum").fillna(0)
    heat = go.Figure(data=go.Heatmap(z=piv.values, x=piv.columns, y=piv.index, colorscale=[[0, LIGHT_GREY],[1, PRIMARY_BLUE]]))
    heat.update_layout(height=360, margin=dict(l=10,r=10,t=10,b=10))
    st.plotly_chart(heat, use_container_width=True)

# -----------------------
# Diagnostics Tab
# -----------------------
with tab_diagnostics:
    st.subheader("Data Quality & Notes")
    issues = []
    if data["Amount"].abs().sum() == 0:
        issues.append("Amounts look zero â€” ensure Amount column is present (positive for sells, negative or positive for buys; we will sign by type).")
    if data["Units"].fillna(0).sum() == 0:
        issues.append("Units missing â€” NAV-based valuation may be limited.")
    if not data["CurrentValue"].notna().any():
        issues.append("No CurrentValue provided â€” portfolio value is approximated. Add CurrentValue per scheme for precise XIRR.")
    if len(issues)==0:
        st.success("No major issues detected. You're good to go âœ¨")
    else:
        for msg in issues:
            st.warning(msg)

    st.markdown(
        f"""
        **Tips**
        - To enable *MarketCap* and *Sector* allocations, populate those columns in your upload.
        - XIRR comparisons are shown **vs NIFTY 500 XIRR** (as requested) in the Performance tab.
        - Benchmark prices are fetched via Yahoo Finance ETF proxies when available; otherwise a synthetic fallback is used.
        - For the cleanest results, upload CSV/XLSX using the provided template.
        """
    )

# -----------------------
# Footer
# -----------------------
st.markdown(
    f"""
    <div style='margin-top:24px;padding:14px;border-radius:18px;background:{SOFT_BLUE};border:1px solid {PRIMARY_BLUE}'>
        <div style='display:flex;justify-content:space-between;align-items:center;'>
            <div>
                <strong style='color:{PRIMARY_BLUE}'>3Sigma Partners</strong><br/>
                <span style='color:{MID_GREY}'>Wealth Advisory â€¢ Portfolio Analytics</span>
            </div>
            <div style='text-align:right;color:{MID_GREY}'>
                Need a white-label deployment? Contact Us
            </div>
        </div>
    </div>
    """,
    unsafe_allow_html=True,
)
